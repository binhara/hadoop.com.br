/**
 * Modern Stacks JavaScript
 * Handles interactive functionality for modern open-source stacks
 */

// Initialize modern stacks functionality
document.addEventListener('DOMContentLoaded', function() {
    initializeStackTabs();
    initializeCodeExamples();
    initializeInteractiveFeatures();
    initializeAnalytics();
});

/**
 * Initialize stack tabs with enhanced functionality
 */
function initializeStackTabs() {
    const tabs = document.querySelectorAll('#stackTabs button[data-bs-toggle="tab"]');
    
    tabs.forEach(tab => {
        tab.addEventListener('shown.bs.tab', function(e) {
            const targetId = e.target.getAttribute('data-bs-target');
            trackStackView(targetId);
            animateMetrics(targetId);
        });
    });
}

/**
 * Animate metrics bars when tab is shown
 */
function animateMetrics(tabId) {
    const tabPane = document.querySelector(tabId);
    if (!tabPane) return;
    
    const progressBars = tabPane.querySelectorAll('.progress-bar');
    progressBars.forEach(bar => {
        const width = bar.style.width;
        bar.style.width = '0%';
        setTimeout(() => {
            bar.style.transition = 'width 1s ease-in-out';
            bar.style.width = width;
        }, 100);
    });
}

/**
 * Initialize code examples with syntax highlighting and copy functionality
 */
function initializeCodeExamples() {
    const codeBlocks = document.querySelectorAll('.code-example code');
    
    codeBlocks.forEach(block => {
        // Add copy button
        const copyButton = document.createElement('button');
        copyButton.className = 'btn btn-outline-success btn-sm copy-btn';
        copyButton.innerHTML = 'ðŸ“‹ Copiar';
        copyButton.style.cssText = 'position: absolute; top: 10px; right: 10px; z-index: 10;';
        
        // Make parent relative for absolute positioning
        block.parentElement.style.position = 'relative';
        block.parentElement.appendChild(copyButton);
        
        copyButton.addEventListener('click', function() {
            copyToClipboard(block.textContent);
            this.innerHTML = 'âœ… Copiado!';
            setTimeout(() => {
                this.innerHTML = 'ðŸ“‹ Copiar';
            }, 2000);
        });
    });
}

/**
 * Copy text to clipboard
 */
function copyToClipboard(text) {
    if (navigator.clipboard) {
        navigator.clipboard.writeText(text).then(() => {
            showNotification('CÃ³digo copiado para a Ã¡rea de transferÃªncia!', 'success');
        });
    } else {
        // Fallback for older browsers
        const textArea = document.createElement('textarea');
        textArea.value = text;
        document.body.appendChild(textArea);
        textArea.select();
        document.execCommand('copy');
        document.body.removeChild(textArea);
        showNotification('CÃ³digo copiado para a Ã¡rea de transferÃªncia!', 'success');
    }
}

/**
 * Download code examples
 */
window.downloadCode = function(codeType) {
    let content = '';
    let filename = '';
    
    switch (codeType) {
        case 'lakehouse-docker':
            content = generateLakehouseDockerCompose();
            filename = 'lakehouse-stack-docker-compose.yml';
            break;
        case 'streaming-k8s':
            content = generateStreamingKubernetes();
            filename = 'streaming-stack-kubernetes.yml';
            break;
        default:
            console.error('Unknown code type:', codeType);
            return;
    }
    
    downloadTextFile(content, filename);
    
    // Track download
    if (typeof gtag !== 'undefined') {
        gtag('event', 'code_download', {
            event_category: 'Modern Stacks',
            event_label: codeType
        });
    }
};

/**
 * Generate complete Lakehouse Docker Compose
 */
function generateLakehouseDockerCompose() {
    return `# Modern Lakehouse Stack - Docker Compose
# Generated by Portal Big Data - hadoop.com.br

version: '3.8'

services:
  # MinIO - S3 Compatible Object Storage
  minio:
    image: minio/minio:latest
    container_name: lakehouse-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
      MINIO_REGION_NAME: us-east-1
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Spark Master
  spark-master:
    image: bitnami/spark:3.5
    container_name: lakehouse-spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    volumes:
      - ./spark-config:/opt/bitnami/spark/conf
      - ./spark-apps:/opt/spark-apps
    depends_on:
      - minio

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.5
    container_name: lakehouse-spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
    volumes:
      - ./spark-config:/opt/bitnami/spark/conf
      - ./spark-apps:/opt/spark-apps
    depends_on:
      - spark-master

  # Trino Coordinator
  trino:
    image: trinodb/trino:latest
    container_name: lakehouse-trino
    ports:
      - "8081:8080"
    volumes:
      - ./trino-config:/etc/trino
      - ./trino-catalogs:/etc/trino/catalog
    environment:
      - TRINO_ENVIRONMENT=production
    depends_on:
      - minio
      - hive-metastore

  # Hive Metastore
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: lakehouse-metastore
    ports:
      - "9083:9083"
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - SERVICE_OPTS=-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive
    depends_on:
      - postgres

  # PostgreSQL for Metastore
  postgres:
    image: postgres:13
    container_name: lakehouse-postgres
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-metastore.sql:/docker-entrypoint-initdb.d/init-metastore.sql

  # Apache Superset
  superset:
    image: apache/superset:latest
    container_name: lakehouse-superset
    ports:
      - "8088:8088"
    environment:
      - SUPERSET_SECRET_KEY=your-secret-key-here
    volumes:
      - superset-data:/app/superset_home
    depends_on:
      - trino

  # Apache Airflow
  airflow-webserver:
    image: apache/airflow:2.8.0
    container_name: lakehouse-airflow
    ports:
      - "8082:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=your-fernet-key-here
      - AIRFLOW__WEBSERVER__SECRET_KEY=your-secret-key-here
    volumes:
      - ./airflow-dags:/opt/airflow/dags
      - ./airflow-logs:/opt/airflow/logs
      - ./airflow-plugins:/opt/airflow/plugins
    depends_on:
      - postgres-airflow

  # PostgreSQL for Airflow
  postgres-airflow:
    image: postgres:13
    container_name: lakehouse-postgres-airflow
    environment:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data

volumes:
  minio-data:
  postgres-data:
  postgres-airflow-data:
  superset-data:

networks:
  default:
    name: lakehouse-network

# Configuration files needed:
# 1. ./spark-config/spark-defaults.conf
# 2. ./trino-config/config.properties
# 3. ./trino-catalogs/delta.properties
# 4. ./airflow-dags/ (your DAG files)
# 5. ./init-metastore.sql

# To start the stack:
# docker-compose up -d

# Access URLs:
# - MinIO Console: http://localhost:9001
# - Spark Master UI: http://localhost:8080
# - Trino UI: http://localhost:8081
# - Superset: http://localhost:8088
# - Airflow: http://localhost:8082
`;
}

/**
 * Generate complete Streaming Kubernetes configuration
 */
function generateStreamingKubernetes() {
    return `# Modern Streaming Stack - Kubernetes
# Generated by Portal Big Data - hadoop.com.br

---
# Zookeeper Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
  namespace: streaming
spec:
  replicas: 3
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:latest
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
        - name: ZOOKEEPER_SERVERS
          value: "zookeeper-0:2888:3888;zookeeper-1:2888:3888;zookeeper-2:2888:3888"
        volumeMounts:
        - name: zookeeper-data
          mountPath: /var/lib/zookeeper/data
        - name: zookeeper-logs
          mountPath: /var/lib/zookeeper/log
      volumes:
      - name: zookeeper-data
        persistentVolumeClaim:
          claimName: zookeeper-data-pvc
      - name: zookeeper-logs
        persistentVolumeClaim:
          claimName: zookeeper-logs-pvc

---
# Kafka Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-cluster
  namespace: streaming
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:latest
        ports:
        - containerPort: 9092
        - containerPort: 9093
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "2"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "1073741824"
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: "300000"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
      volumes:
      - name: kafka-data
        persistentVolumeClaim:
          claimName: kafka-data-pvc

---
# Flink JobManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-jobmanager
  namespace: streaming
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flink
      component: jobmanager
  template:
    metadata:
      labels:
        app: flink
        component: jobmanager
    spec:
      containers:
      - name: jobmanager
        image: flink:1.18
        args: ["jobmanager"]
        ports:
        - containerPort: 6123
          name: rpc
        - containerPort: 6124
          name: blob-server
        - containerPort: 8081
          name: webui
        env:
        - name: FLINK_PROPERTIES
          value: |
            jobmanager.rpc.address: flink-jobmanager
            taskmanager.numberOfTaskSlots: 4
            parallelism.default: 2
            jobmanager.memory.process.size: 1600m
            taskmanager.memory.process.size: 1728m
            state.backend: rocksdb
            state.checkpoints.dir: file:///checkpoints
            state.savepoints.dir: file:///savepoints
        volumeMounts:
        - name: flink-checkpoints
          mountPath: /checkpoints
        - name: flink-savepoints
          mountPath: /savepoints
      volumes:
      - name: flink-checkpoints
        persistentVolumeClaim:
          claimName: flink-checkpoints-pvc
      - name: flink-savepoints
        persistentVolumeClaim:
          claimName: flink-savepoints-pvc

---
# Flink TaskManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-taskmanager
  namespace: streaming
spec:
  replicas: 3
  selector:
    matchLabels:
      app: flink
      component: taskmanager
  template:
    metadata:
      labels:
        app: flink
        component: taskmanager
    spec:
      containers:
      - name: taskmanager
        image: flink:1.18
        args: ["taskmanager"]
        ports:
        - containerPort: 6122
          name: rpc
        - containerPort: 6125
          name: query-state
        env:
        - name: FLINK_PROPERTIES
          value: |
            jobmanager.rpc.address: flink-jobmanager
            taskmanager.numberOfTaskSlots: 4
            parallelism.default: 2
            jobmanager.memory.process.size: 1600m
            taskmanager.memory.process.size: 1728m
            state.backend: rocksdb
            state.checkpoints.dir: file:///checkpoints
            state.savepoints.dir: file:///savepoints
        volumeMounts:
        - name: flink-checkpoints
          mountPath: /checkpoints
        - name: flink-savepoints
          mountPath: /savepoints
      volumes:
      - name: flink-checkpoints
        persistentVolumeClaim:
          claimName: flink-checkpoints-pvc
      - name: flink-savepoints
        persistentVolumeClaim:
          claimName: flink-savepoints-pvc

---
# ClickHouse Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clickhouse
  namespace: streaming
spec:
  replicas: 1
  selector:
    matchLabels:
      app: clickhouse
  template:
    metadata:
      labels:
        app: clickhouse
    spec:
      containers:
      - name: clickhouse
        image: clickhouse/clickhouse-server:latest
        ports:
        - containerPort: 8123
          name: http
        - containerPort: 9000
          name: native
        env:
        - name: CLICKHOUSE_DB
          value: "streaming"
        - name: CLICKHOUSE_USER
          value: "admin"
        - name: CLICKHOUSE_PASSWORD
          value: "password"
        volumeMounts:
        - name: clickhouse-data
          mountPath: /var/lib/clickhouse
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/config.xml
          subPath: config.xml
      volumes:
      - name: clickhouse-data
        persistentVolumeClaim:
          claimName: clickhouse-data-pvc
      - name: clickhouse-config
        configMap:
          name: clickhouse-config

---
# Services
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: streaming
spec:
  selector:
    app: zookeeper
  ports:
  - port: 2181
    targetPort: 2181

---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: streaming
spec:
  selector:
    app: kafka
  ports:
  - port: 9092
    targetPort: 9092

---
apiVersion: v1
kind: Service
metadata:
  name: flink-jobmanager
  namespace: streaming
spec:
  selector:
    app: flink
    component: jobmanager
  ports:
  - name: rpc
    port: 6123
    targetPort: 6123
  - name: blob-server
    port: 6124
    targetPort: 6124
  - name: webui
    port: 8081
    targetPort: 8081

---
apiVersion: v1
kind: Service
metadata:
  name: clickhouse
  namespace: streaming
spec:
  selector:
    app: clickhouse
  ports:
  - name: http
    port: 8123
    targetPort: 8123
  - name: native
    port: 9000
    targetPort: 9000

---
# Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: streaming

# To deploy:
# kubectl apply -f streaming-stack-kubernetes.yml

# Access services:
# kubectl port-forward svc/flink-jobmanager 8081:8081 -n streaming
# kubectl port-forward svc/clickhouse 8123:8123 -n streaming
`;
}

/**
 * Initialize interactive features
 */
function initializeInteractiveFeatures() {
    // Stack assessment functionality
    window.startStackAssessment = function() {
        showStackAssessmentModal();
    };
    
    // PoC template download
    window.downloadPoCTemplate = function() {
        const content = generatePoCTemplate();
        downloadTextFile(content, 'modern-stack-poc-template.md');
    };
    
    // Implementation guide
    window.showImplementationGuide = function(stackType) {
        showImplementationModal(stackType);
    };
    
    // Optimization guide
    window.showOptimizationGuide = function() {
        showOptimizationModal();
    };
}

/**
 * Show stack assessment modal
 */
function showStackAssessmentModal() {
    const modalHtml = `
        <div class="modal fade" id="stackAssessmentModal" tabindex="-1">
            <div class="modal-dialog modal-lg">
                <div class="modal-content matrix-card">
                    <div class="modal-header">
                        <h5 class="modal-title">ðŸŽ¯ Stack Assessment</h5>
                        <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
                    </div>
                    <div class="modal-body">
                        <div id="assessmentQuestions">
                            <div class="question active" data-question="1">
                                <h6>1. Qual Ã© o seu principal caso de uso?</h6>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="usecase" value="batch" id="batch">
                                    <label class="form-check-label" for="batch">Processamento Batch/ETL</label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="usecase" value="analytics" id="analytics">
                                    <label class="form-check-label" for="analytics">Analytics/BI</label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="usecase" value="streaming" id="streaming">
                                    <label class="form-check-label" for="streaming">Real-time/Streaming</label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="usecase" value="ml" id="ml">
                                    <label class="form-check-label" for="ml">Machine Learning</label>
                                </div>
                            </div>
                        </div>
                        <div class="mt-3">
                            <button class="btn btn-success" onclick="processAssessment()">Ver RecomendaÃ§Ã£o</button>
                        </div>
                        <div id="assessmentResult" class="mt-4" style="display: none;"></div>
                    </div>
                </div>
            </div>
        </div>
    `;
    
    document.body.insertAdjacentHTML('beforeend', modalHtml);
    const modal = new bootstrap.Modal(document.getElementById('stackAssessmentModal'));
    modal.show();
    
    // Clean up modal after hiding
    document.getElementById('stackAssessmentModal').addEventListener('hidden.bs.modal', function() {
        this.remove();
    });
}

/**
 * Process stack assessment
 */
window.processAssessment = function() {
    const usecase = document.querySelector('input[name="usecase"]:checked')?.value;
    
    if (!usecase) {
        showNotification('Por favor, selecione uma opÃ§Ã£o', 'warning');
        return;
    }
    
    const recommendations = {
        batch: {
            stack: 'Lakehouse Stack',
            description: 'Spark + Delta Lake + Trino Ã© ideal para processamento batch moderno',
            benefits: ['Performance 5x melhor', 'ACID transactions', 'Schema evolution']
        },
        analytics: {
            stack: 'Analytics Stack',
            description: 'Trino + ClickHouse oferece queries interativas ultra-rÃ¡pidas',
            benefits: ['Queries sub-segundo', 'SQL padrÃ£o', 'MÃºltiplas fontes']
        },
        streaming: {
            stack: 'Streaming Stack',
            description: 'Kafka + Flink para processamento em tempo real',
            benefits: ['LatÃªncia < 100ms', 'Exactly-once', 'Complex event processing']
        },
        ml: {
            stack: 'ML Stack',
            description: 'Ray + MLflow para MLOps moderno',
            benefits: ['MLOps nativo', 'Auto-scaling', 'Feature store integrado']
        }
    };
    
    const rec = recommendations[usecase];
    const resultHtml = `
        <div class="alert alert-success">
            <h6>ðŸŽ¯ RecomendaÃ§Ã£o: ${rec.stack}</h6>
            <p>${rec.description}</p>
            <ul>
                ${rec.benefits.map(benefit => `<li>${benefit}</li>`).join('')}
            </ul>
            <button class="btn btn-outline-success btn-sm" onclick="showStackDetails('${usecase}')">
                Ver Detalhes da Stack
            </button>
        </div>
    `;
    
    document.getElementById('assessmentResult').innerHTML = resultHtml;
    document.getElementById('assessmentResult').style.display = 'block';
};

/**
 * Show stack details
 */
window.showStackDetails = function(stackType) {
    const tabMap = {
        batch: 'lakehouse-tab',
        analytics: 'analytics-tab',
        streaming: 'streaming-tab',
        ml: 'ml-tab'
    };
    
    // Close modal
    const modal = bootstrap.Modal.getInstance(document.getElementById('stackAssessmentModal'));
    modal.hide();
    
    // Activate corresponding tab
    setTimeout(() => {
        const tab = document.getElementById(tabMap[stackType]);
        if (tab) {
            tab.click();
            tab.scrollIntoView({ behavior: 'smooth' });
        }
    }, 500);
};

/**
 * Generate PoC template
 */
function generatePoCTemplate() {
    return `# Modern Stack Proof of Concept Template
# Generated by Portal Big Data - hadoop.com.br

## Objetivo do PoC

Validar a viabilidade tÃ©cnica e benefÃ­cios de migraÃ§Ã£o do Hadoop para uma stack moderna.

## Escopo do PoC

### Dados de Teste
- [ ] Dataset representativo (10-100GB)
- [ ] Casos de uso crÃ­ticos selecionados
- [ ] MÃ©tricas de baseline do Hadoop

### Tecnologias a Testar
- [ ] Stack selecionada baseada no assessment
- [ ] ConfiguraÃ§Ã£o otimizada para PoC
- [ ] Monitoramento e mÃ©tricas

### CritÃ©rios de Sucesso
- [ ] Performance igual ou superior
- [ ] Funcionalidades mantidas
- [ ] Facilidade de operaÃ§Ã£o
- [ ] Custo-benefÃ­cio positivo

## Cronograma (4 semanas)

### Semana 1: Setup
- [ ] Provisionar infraestrutura
- [ ] Instalar e configurar stack
- [ ] Preparar dados de teste
- [ ] Configurar monitoramento

### Semana 2: ImplementaÃ§Ã£o
- [ ] Migrar jobs crÃ­ticos
- [ ] Configurar pipelines
- [ ] Implementar testes
- [ ] Validar funcionalidades

### Semana 3: Testes
- [ ] Testes de performance
- [ ] Testes de carga
- [ ] ValidaÃ§Ã£o de resultados
- [ ] Coleta de mÃ©tricas

### Semana 4: AnÃ¡lise
- [ ] ComparaÃ§Ã£o com baseline
- [ ] AnÃ¡lise de custos
- [ ] DocumentaÃ§Ã£o de resultados
- [ ] RecomendaÃ§Ãµes finais

## MÃ©tricas a Coletar

### Performance
- Tempo de processamento
- Throughput (MB/s)
- LatÃªncia de queries
- UtilizaÃ§Ã£o de recursos

### Operacional
- Facilidade de deployment
- Tempo de troubleshooting
- Complexidade de configuraÃ§Ã£o
- Disponibilidade do sistema

### Custo
- Custo de infraestrutura
- Custo de licenÃ§as
- Custo operacional
- ROI estimado

## Riscos e MitigaÃ§Ãµes

### Riscos TÃ©cnicos
- Incompatibilidade de dados
- Performance inferior
- Problemas de integraÃ§Ã£o

### MitigaÃ§Ãµes
- Backup completo dos dados
- Ambiente isolado para testes
- Rollback plan definido

## EntregÃ¡veis

- [ ] RelatÃ³rio de comparaÃ§Ã£o tÃ©cnica
- [ ] AnÃ¡lise de custo-benefÃ­cio
- [ ] RecomendaÃ§Ãµes de migraÃ§Ã£o
- [ ] Plano de implementaÃ§Ã£o

---
Para mais recursos: https://hadoop.com.br/sair-hadoop/stacks-modernas/
`;
}

/**
 * Track stack views for analytics
 */
function trackStackView(stackId) {
    if (typeof gtag !== 'undefined') {
        gtag('event', 'stack_view', {
            event_category: 'Modern Stacks',
            event_label: stackId.replace('#', '').replace('-stack', '')
        });
    }
}

/**
 * Initialize analytics tracking
 */
function initializeAnalytics() {
    // Track page view
    if (typeof gtag !== 'undefined') {
        gtag('event', 'page_view', {
            page_title: 'Modern Stacks',
            page_location: window.location.href
        });
    }
    
    // Track scroll depth
    let maxScroll = 0;
    window.addEventListener('scroll', function() {
        const scrollPercent = Math.round((window.scrollY / (document.body.scrollHeight - window.innerHeight)) * 100);
        if (scrollPercent > maxScroll && scrollPercent % 25 === 0) {
            maxScroll = scrollPercent;
            if (typeof gtag !== 'undefined') {
                gtag('event', 'scroll', {
                    event_category: 'Engagement',
                    event_label: `${scrollPercent}%`,
                    value: scrollPercent
                });
            }
        }
    });
}

/**
 * Utility functions
 */
function downloadTextFile(content, filename) {
    const element = document.createElement('a');
    element.setAttribute('href', 'data:text/plain;charset=utf-8,' + encodeURIComponent(content));
    element.setAttribute('download', filename);
    element.style.display = 'none';
    document.body.appendChild(element);
    element.click();
    document.body.removeChild(element);
    
    showNotification(`Template "${filename}" baixado com sucesso!`, 'success');
}

function showNotification(message, type = 'info') {
    const notification = document.createElement('div');
    notification.className = `alert alert-${type} alert-dismissible fade show position-fixed`;
    notification.style.cssText = 'top: 20px; right: 20px; z-index: 9999; min-width: 300px;';
    notification.innerHTML = `
        ${message}
        <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
    `;
    
    document.body.appendChild(notification);
    
    setTimeout(() => {
        if (notification.parentNode) {
            notification.parentNode.removeChild(notification);
        }
    }, 5000);
}

/**
 * Export functions for external use
 */
window.ModernStacks = {
    downloadCode,
    startStackAssessment,
    downloadPoCTemplate,
    showImplementationGuide,
    showOptimizationGuide
};